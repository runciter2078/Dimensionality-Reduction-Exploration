{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-001",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction Techniques: PCA, t-SNE, and UMAP\n",
    "\n",
    "In this notebook, we explore three popular dimensionality reduction methods—**Principal Component Analysis (PCA)**, **t-SNE**, and **UMAP**—with detailed technical explanations and code examples. We begin with a synthetic 2D dataset to illustrate PCA, apply PCA to the Iris dataset, and finally compare the results of t-SNE, UMAP, and PCA on a synthetic 3D dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objectives-002",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Understand the theory behind PCA and how it finds the directions of maximum variance.\n",
    "- Apply PCA to both synthetic and real datasets (Iris data) for dimensionality reduction.\n",
    "- Implement t-SNE and UMAP for non-linear dimensionality reduction and compare their performance with PCA.\n",
    "- Visualize and interpret the results of each algorithm in terms of cluster structure and variance preservation."
   ]
  },
  {
   "cell_type": "code",
   "id": "install-003",
   "metadata": {},
   "source": [
    "# Install necessary libraries (uncomment and run if not already installed)\n",
    "!pip install numpy pandas matplotlib scikit-learn plotly umap-learn"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "imports-004",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import make_blobs, load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import umap.umap_ as umap\n",
    "import plotly.express as px\n",
    "\n",
    "# Configure matplotlib inline (if using Jupyter Notebook)\n",
    "%matplotlib inline"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "part1-title-005",
   "metadata": {},
   "source": [
    "## Part I: PCA on a Synthetic 2D Dataset\n",
    "\n",
    "In this section, we generate a bivariate normal dataset and use PCA to find its principal components. We then project the data onto these axes and visualize both the original data and its projections."
   ]
  },
  {
   "cell_type": "code",
   "id": "create-2d-data-006",
   "metadata": {},
   "source": [
    "# Generate a 2D dataset using a bivariate normal distribution\n",
    "np.random.seed(42)\n",
    "mean = [0, 0]\n",
    "cov = [[3, 2], [2, 2]]  \n",
    "X_2d = np.random.multivariate_normal(mean, cov, 200)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "plot-original-007",
   "metadata": {},
   "source": [
    "### Visualize the Original 2D Data\n",
    "\n",
    "We start by plotting a scatter plot of our two features to see the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "id": "scatter-2d-008",
   "metadata": {},
   "source": [
    "# Scatter plot of the original 2D data\n",
    "plt.figure()\n",
    "plt.scatter(X_2d[:, 0], X_2d[:, 1], edgecolor='k', alpha=0.7)\n",
    "plt.title(\"Scatter Plot of 2D Bivariate Normal Distribution\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "pca-2d-explanation-009",
   "metadata": {},
   "source": [
    "### Apply PCA to the 2D Data\n",
    "\n",
    "We initialize a PCA model with 2 components, fit it to our data, and then transform the data into its principal component space. The principal components represent the directions of maximum variance."
   ]
  },
  {
   "cell_type": "code",
   "id": "apply-pca-010",
   "metadata": {},
   "source": [
    "# Apply PCA on the 2D data\n",
    "pca_2d = PCA(n_components=2)\n",
    "X_pca_2d = pca_2d.fit_transform(X_2d)\n",
    "\n",
    "components = pca_2d.components_\n",
    "explained_variance_ratio = pca_2d.explained_variance_ratio_\n",
    "\n",
    "print(\"Principal Components:\\n\", components)\n",
    "print(\"Explained Variance Ratio:\", explained_variance_ratio)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "project-data-011",
   "metadata": {},
   "source": [
    "### Projecting Data onto Principal Component Axes\n",
    "\n",
    "The new coordinates of each point along a principal component can be computed as the dot product of the data with that component. We then map these projections back to the original feature space for visualization."
   ]
  },
  {
   "cell_type": "code",
   "id": "project-011",
   "metadata": {},
   "source": [
    "# Compute projections onto the two principal components\n",
    "projection_pc1 = np.dot(X_2d, components[0])\n",
    "projection_pc2 = np.dot(X_2d, components[1])\n",
    "\n",
    "# Map the projections back to the original feature space\n",
    "x_pc1 = projection_pc1 * components[0][0]\n",
    "y_pc1 = projection_pc1 * components[0][1]\n",
    "x_pc2 = projection_pc2 * components[1][0]\n",
    "y_pc2 = projection_pc2 * components[1][1]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "plot-projections-012",
   "metadata": {},
   "source": [
    "### Visualize the Projections\n",
    "\n",
    "Here, we overlay the original data with its projections onto the first and second principal components."
   ]
  },
  {
   "cell_type": "code",
   "id": "plot-2d-projections-013",
   "metadata": {},
   "source": [
    "# Plot the original data and its projections onto PC1 and PC2\n",
    "plt.figure()\n",
    "plt.scatter(X_2d[:, 0], X_2d[:, 1], label='Original Data', c='gray', edgecolor='k', alpha=0.6)\n",
    "plt.scatter(x_pc1, y_pc1, marker='X', s=70, c='r', edgecolor='k', alpha=0.5, label='Projection on PC1')\n",
    "plt.scatter(x_pc2, y_pc2, marker='X', s=70, c='b', edgecolor='k', alpha=0.5, label='Projection on PC2')\n",
    "plt.title('2D Data Projected onto Principal Components')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "reflection-pca-014",
   "metadata": {},
   "source": [
    "### Reflection on PCA (2D Data)\n",
    "\n",
    "The printed explained variance ratios indicate how much of the total variance each principal component captures. In many cases, the first principal component captures a very high percentage of the variance, demonstrating the main direction of variation in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2-title-015",
   "metadata": {},
   "source": [
    "## Part II: PCA on the Iris Dataset\n",
    "\n",
    "Next, we apply PCA to a real-world dataset—the Iris dataset. This dataset has four features, and we will reduce it to two principal components to visualize how well the data can be separated based on the flower species."
   ]
  },
  {
   "cell_type": "code",
   "id": "iris-data-016",
   "metadata": {},
   "source": [
    "# Load and standardize the Iris dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "target_names = iris.target_names\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_iris_scaled = scaler.fit_transform(X_iris)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "pca-iris-explanation-017",
   "metadata": {},
   "source": [
    "### Apply PCA to the Iris Dataset\n",
    "\n",
    "We now reduce the Iris dataset from four to two dimensions using PCA. This helps in visualizing the separability of the species."
   ]
  },
  {
   "cell_type": "code",
   "id": "apply-pca-iris-018",
   "metadata": {},
   "source": [
    "# Apply PCA on the Iris dataset\n",
    "pca_iris = PCA(n_components=2)\n",
    "X_iris_pca = pca_iris.fit_transform(X_iris_scaled)\n",
    "\n",
    "print(\"Explained Variance Ratio (Iris):\", pca_iris.explained_variance_ratio_)\n",
    "print(\"Combined Variance Explained:\", np.sum(pca_iris.explained_variance_ratio_)*100, \"%\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "plot-iris-pca-019",
   "metadata": {},
   "source": [
    "# Plot the PCA-transformed Iris data\n",
    "plt.figure(figsize=(8,6))\n",
    "colors = ['navy', 'turquoise', 'darkorange']\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "    plt.scatter(X_iris_pca[y_iris == i, 0], X_iris_pca[y_iris == i, 1], color=color, s=50, edgecolor='k', alpha=0.7, label=target_name)\n",
    "plt.title('PCA: 2D Reduction of the Iris Dataset')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "reflection-iris-020",
   "metadata": {},
   "source": [
    "### Reflection on the Iris PCA Result\n",
    "\n",
    "The two principal components capture a large portion of the variance in the Iris dataset. This reduction helps in visualizing the natural grouping of the flower species, even though some overlap may still exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3-title-021",
   "metadata": {},
   "source": [
    "## Part III: Comparing t-SNE, UMAP, and PCA on a Synthetic 3D Dataset\n",
    "\n",
    "In this section, we generate a synthetic dataset with clusters in a 3-dimensional space. We then apply t-SNE, UMAP, and PCA to reduce the data to 2 dimensions. This comparison helps illustrate the strengths and trade-offs of each algorithm in preserving cluster structure and local relationships."
   ]
  },
  {
   "cell_type": "code",
   "id": "create-3d-data-022",
   "metadata": {},
   "source": [
    "# Generate a synthetic 3D dataset with 4 clusters\n",
    "centers = [[2, -6, -6], [-1, 9, 4], [-8, 7, 2], [4, 7, 9]]\n",
    "cluster_std = [1, 1, 2, 3.5]\n",
    "X_3d, labels_3d = make_blobs(n_samples=500, centers=centers, n_features=3, cluster_std=cluster_std, random_state=42)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "plot-3d-interactive-023",
   "metadata": {},
   "source": [
    "### Interactive 3D Visualization\n",
    "\n",
    "Below is an interactive 3D scatter plot of the synthetic data using Plotly. Use the tools provided in the plot to rotate, zoom, and pan."
   ]
  },
  {
   "cell_type": "code",
   "id": "plotly-3d-024",
   "metadata": {},
   "source": [
    "# Create a DataFrame and plot an interactive 3D scatter plot\n",
    "df_3d = pd.DataFrame(X_3d, columns=['X', 'Y', 'Z'])\n",
    "fig = px.scatter_3d(df_3d, x='X', y='Y', z='Z', color=labels_3d.astype(str), opacity=0.7,\n",
    "                     title=\"Interactive 3D Scatter Plot of Synthetic Data\")\n",
    "fig.update_traces(marker=dict(size=5, line=dict(width=1, color='black')), showlegend=False)\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "standardize-3d-025",
   "metadata": {},
   "source": [
    "### Standardize the 3D Data\n",
    "\n",
    "Standardization ensures that each feature contributes equally to the dimensionality reduction process."
   ]
  },
  {
   "cell_type": "code",
   "id": "scale-3d-026",
   "metadata": {},
   "source": [
    "scaler_3d = StandardScaler()\n",
    "X_3d_scaled = scaler_3d.fit_transform(X_3d)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "tsne-3d-027",
   "metadata": {},
   "source": [
    "### Apply t-SNE to the 3D Data\n",
    "\n",
    "We reduce the dimensionality from 3D to 2D using t-SNE. The algorithm is particularly good at preserving local structure, although the results may vary with different perplexity values."
   ]
  },
  {
   "cell_type": "code",
   "id": "apply-tsne-028",
   "metadata": {},
   "source": [
    "tsne_model = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\n",
    "X_tsne = tsne_model.fit_transform(X_3d_scaled)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "plot-tsne-029",
   "metadata": {},
   "source": [
    "### Plot the t-SNE Projection\n",
    "\n",
    "The following scatter plot shows the 2D projection obtained from t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "id": "plot-tsne-code-030",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=labels_3d, cmap='viridis', s=50, edgecolor='k', alpha=0.7)\n",
    "plt.title('2D t-SNE Projection of 3D Synthetic Data')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "umap-3d-031",
   "metadata": {},
   "source": [
    "### Apply UMAP to the 3D Data\n",
    "\n",
    "UMAP is another non-linear dimensionality reduction technique that tends to preserve both local and global structure. Here, we set `min_dist=0.5` and `spread=1` as parameters."
   ]
  },
  {
   "cell_type": "code",
   "id": "apply-umap-032",
   "metadata": {},
   "source": [
    "umap_model = umap.UMAP(n_components=2, random_state=42, min_dist=0.5, spread=1, n_jobs=1)\n",
    "X_umap = umap_model.fit_transform(X_3d_scaled)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "plot-umap-033",
   "metadata": {},
   "source": [
    "### Plot the UMAP Projection\n",
    "\n",
    "We now visualize the 2D projection obtained from UMAP."
   ]
  },
  {
   "cell_type": "code",
   "id": "plot-umap-code-034",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_umap[:, 0], X_umap[:, 1], c=labels_3d, cmap='viridis', s=50, edgecolor='k', alpha=0.7)\n",
    "plt.title('2D UMAP Projection of 3D Synthetic Data')\n",
    "plt.xlabel('UMAP Component 1')\n",
    "plt.ylabel('UMAP Component 2')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "pca-3d-035",
   "metadata": {},
   "source": [
    "### Apply PCA to the 3D Data\n",
    "\n",
    "Finally, we use PCA to reduce the 3D data to 2 dimensions. This serves as a baseline for comparison with t-SNE and UMAP."
   ]
  },
  {
   "cell_type": "code",
   "id": "apply-pca-3d-036",
   "metadata": {},
   "source": [
    "pca_3d = PCA(n_components=2)\n",
    "X_pca_3d = pca_3d.fit_transform(X_3d_scaled)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "plot-pca-3d-037",
   "metadata": {},
   "source": [
    "### Plot the PCA Projection for 3D Data\n",
    "\n",
    "The following scatter plot shows the 2D projection from PCA."
   ]
  },
  {
   "cell_type": "code",
   "id": "plot-pca-3d-code-038",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca_3d[:, 0], X_pca_3d[:, 1], c=labels_3d, cmap='viridis', s=50, edgecolor='k', alpha=0.7)\n",
    "plt.title('2D PCA Projection of 3D Synthetic Data')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "reflection-3d-039",
   "metadata": {},
   "source": [
    "### Reflection on the 3D Data Projections\n",
    "\n",
    "Compare the three 2D projections obtained from t-SNE, UMAP, and PCA:\n",
    "\n",
    "- **t-SNE**: Excellent at preserving local structure; clusters may appear more separated, but results can vary with the perplexity parameter.\n",
    "- **UMAP**: Balances local and global structure; it often preserves more of the overall data connectivity compared to t-SNE.\n",
    "- **PCA**: A linear method that preserves the directions of maximum variance but may not capture non-linear relationships as well as t-SNE or UMAP.\n",
    "\n",
    "Each method has its trade-offs in terms of computational performance and the type of structure they preserve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-040",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to apply PCA, t-SNE, and UMAP to both synthetic and real datasets. We covered:\n",
    "\n",
    "- The theory behind PCA and how to visualize its results on a 2D dataset and the Iris dataset.\n",
    "- The application of t-SNE and UMAP on a synthetic 3D dataset, highlighting how non-linear methods can capture more complex relationships.\n",
    "\n",
    "By comparing the results of these methods, you can choose the best dimensionality reduction technique for your specific problem.\n",
    "\n",
    "Happy coding and exploring your data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
